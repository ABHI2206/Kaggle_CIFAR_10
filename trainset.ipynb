{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import random\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "horse\n",
      "automobile\n",
      "truck\n",
      "frog\n",
      "bird\n",
      "cat\n",
      "ship\n",
      "deer\n",
      "airplane\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "train_num_images = 0\n",
    "images = []\n",
    "y = []\n",
    "Y_dict = {}\n",
    "for dirnames in os.listdir(\"data/train_data\"):\n",
    "    print(dirnames)\n",
    "    Y_dict[dirnames] = i\n",
    "    for filename in os.listdir(\"data/train_data/\"+ dirnames):\n",
    "        train_num_images = train_num_images + 1\n",
    "        #print(filenames,\"\\n\")\n",
    "        # img = mpimg.imread(\"data/train_valid/\"+ dirnames + \"/\" + filename) or  img =  misc.imread(\"data/train_valid/\"+ dirnames + \"/\" + filename)\n",
    "        img =  misc.imread(\"data/train_data/\"+ dirnames + \"/\" + filename)\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            y.append(i)\n",
    "#             print(img)\n",
    "#             print(y)\n",
    "            \n",
    "    i = i + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'horse': 1, 'automobile': 2, 'truck': 3, 'frog': 4, 'bird': 5, 'cat': 6, 'ship': 7, 'deer': 8, 'airplane': 9}\n"
     ]
    }
   ],
   "source": [
    "print(Y_dict)\n",
    "# print(x)\n",
    "# print(y)\n",
    "# print(images)\n",
    "# plt.imshow(x[0])\n",
    "# print(y[0])\n",
    "# plt.show()\n",
    "# plt.imshow(images[1])\n",
    "# plt.show()\n",
    "# plt.imshow(images[2])\n",
    "# plt.show()\n",
    "# plt.imshow(images[3])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38cddf3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = list(zip(images, y))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "X,Y = zip(*c)\n",
    "\n",
    "# print (X)\n",
    "# print (Y)\n",
    "plt.imshow(X[0])\n",
    "plt.show()\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "# ANOTHER METHOD OF SHUFFLING BUT SHUFFLE IN PARTICULAR PATTERN DEPENDEING ON RANDOM STATE\n",
    "# from sklearn.utils import shuffle\n",
    "# X,Y = shuffle(images, y, random_state=4)\n",
    "# # print(y)\n",
    "\n",
    "# # print (X)\n",
    "# print (Y)\n",
    "# plt.imshow(X[0])\n",
    "# plt.show()\n",
    "# # print(X[0])\n",
    "# # print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#print(images)\n",
    "# print(images[0].shape)\n",
    "# print(X)\n",
    "# print(Y)\n",
    "train_set = np.reshape(X , (train_num_images,32,32,3) )\n",
    "# print(train_set)\n",
    "print(train_set.shape)\n",
    "# train_out = np.reshape(Y,(train_num_images,1))\n",
    "# print(train_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_out = keras.utils.to_categorical(Y,num_classes=10)\n",
    "print(train_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images = []\n",
    "# for filename in os.listdir(\"myfolder\"):\n",
    "#     img = mpimg.imread(os.path.join(\"myfolder\", filename))\n",
    "#     print(filename)\n",
    "#     if img is not None:\n",
    "#         images.append(img)\n",
    "# print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# imagess = []\n",
    "# y = []\n",
    "# for dirnames in os.listdir(\"data/train_valid\"):\n",
    "#     print(dirnames)\n",
    "#     for filename in os.listdir(\"data/train_valid/\"+ dirnames):\n",
    "#         #print(filenames,\"\\n\")\n",
    "#         img = mpimg.imread(\"data/train_valid/\"+ dirnames + \"/\" + filename)\n",
    "#         if img is not None:\n",
    "#             imagess.append(img)\n",
    "#             y.append(i)\n",
    "#     i = i + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(imagess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOr valid_data\n",
    "\n",
    "i = 0\n",
    "valid_num_images = 0\n",
    "v_images = []\n",
    "v_y = []\n",
    "v_Y_dict = {}\n",
    "for v_dirnames in os.listdir(\"data/valid_data\"):\n",
    "#     print(v_dirnames)\n",
    "    v_Y_dict[v_dirnames] = i\n",
    "    for v_filename in os.listdir(\"data/valid_data/\"+ v_dirnames):\n",
    "        valid_num_images = valid_num_images + 1\n",
    "        #print(filenames,\"\\n\")\n",
    "        # img = mpimg.imread(\"data/train_valid/\"+ dirnames + \"/\" + filename) or  img =  misc.imread(\"data/train_valid/\"+ dirnames + \"/\" + filename)\n",
    "        v_img =  misc.imread(\"data/valid_data/\"+ v_dirnames + \"/\" + v_filename)\n",
    "#         plt.imshow(v_img)\n",
    "#         plt.show()\n",
    "        if img is not None:\n",
    "            v_images.append(v_img)\n",
    "            v_y.append(i)\n",
    "#             print(v_img)\n",
    "#             print(v_y)\n",
    "            \n",
    "    i = i + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'horse': 1, 'automobile': 2, 'truck': 3, 'frog': 4, 'bird': 5, 'cat': 6, 'ship': 7, 'deer': 8, 'airplane': 9}\n"
     ]
    }
   ],
   "source": [
    "print(v_Y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmSLxC5EpEr8QmfJ/41K15CVjegYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38c5aeada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_c = list(zip(v_images, v_y))\n",
    "\n",
    "random.shuffle(v_c)\n",
    "\n",
    "v_X,v_Y = zip(*v_c)\n",
    "\n",
    "# print (v_X)\n",
    "# print (v_Y)\n",
    "plt.imshow(v_X[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(v_Y)\n",
    "validation_set = np.reshape(v_X , (valid_num_images,32,32,3) )\n",
    "# print(train_set)\n",
    "print(validation_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details of the training dataset:**\n",
    "\n",
    "Images are of shape (32,32,3)\n",
    "Training: train_num_images pictures\n",
    "Valid: valid_num_images pictures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "# print(v_Y)\n",
    "validation_out = keras.utils.to_categorical(v_Y,num_classes=10)\n",
    "print(validation_out.shape)\n",
    "# validation_out = np.reshape(v_Y , (valid_num_images,1) )\n",
    "# print(validation_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):  # input_shape here = (32,32,3)\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    \n",
    "    X = keras.layers.Conv2D(6 ,(5,5), strides = (1,1) ,padding = 'same' , name = 'conv0')(X_input)\n",
    "    X = keras.layers.BatchNormalization(axis = 3 , name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.MaxPooling2D((2,2) , name = 'maxpool1')(X)\n",
    "    \n",
    "    X = keras.layers.Conv2D( 16,(5,5), strides = (1,1) , name = 'conv1')(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    X = keras.layers.MaxPool2D((2,2) , name = 'maxpool2')(X)\n",
    "    \n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dense(120 , activation = 'relu' , name = 'fc1')(X)\n",
    "    X = keras.layers.Dense(84 , activation = 'relu' , name = 'fc2')(X)\n",
    "    X = keras.layers.Dense(10 , activation = 'softmax' , name = 'fc3')(X)\n",
    "    \n",
    "    model = keras.models.Model(inputs = X_input , outputs = X , name = 'CifarModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFARModel = build_model(train_set.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 32, 32, 6)         456       \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 32, 32, 6)         24        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 6)         0         \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 16, 16, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 12, 12, 16)        2416      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 12, 12, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 83,214\n",
      "Trainable params: 83,170\n",
      "Non-trainable params: 44\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CIFARModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFARModel.compile(loss='categorical_crossentropy' , optimizer='adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45000/45000 [==============================] - 16s - loss: 1.4832 - acc: 0.4637    \n",
      "Epoch 2/200\n",
      "45000/45000 [==============================] - 14s - loss: 1.2098 - acc: 0.5654    \n",
      "Epoch 3/200\n",
      "45000/45000 [==============================] - 15s - loss: 1.0905 - acc: 0.6123    \n",
      "Epoch 4/200\n",
      "45000/45000 [==============================] - 14s - loss: 1.0041 - acc: 0.6451    \n",
      "Epoch 5/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.9413 - acc: 0.6653    \n",
      "Epoch 6/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.8905 - acc: 0.6856    \n",
      "Epoch 7/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.8473 - acc: 0.6996    \n",
      "Epoch 8/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.8090 - acc: 0.7132    \n",
      "Epoch 9/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.7672 - acc: 0.7298    \n",
      "Epoch 10/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.7345 - acc: 0.7425    \n",
      "Epoch 11/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.7010 - acc: 0.7519    \n",
      "Epoch 12/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.6742 - acc: 0.7600    \n",
      "Epoch 13/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.6422 - acc: 0.7708    \n",
      "Epoch 14/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.6170 - acc: 0.7806    \n",
      "Epoch 15/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.5926 - acc: 0.7880    \n",
      "Epoch 16/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.5664 - acc: 0.7983    \n",
      "Epoch 17/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.5438 - acc: 0.8044    \n",
      "Epoch 18/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.5217 - acc: 0.8128    \n",
      "Epoch 19/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4995 - acc: 0.8200    \n",
      "Epoch 20/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4860 - acc: 0.8270    \n",
      "Epoch 21/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4594 - acc: 0.8360    \n",
      "Epoch 22/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4420 - acc: 0.8428    \n",
      "Epoch 23/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4315 - acc: 0.8449    \n",
      "Epoch 24/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.4104 - acc: 0.8527    \n",
      "Epoch 25/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.3960 - acc: 0.8584    \n",
      "Epoch 26/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.3816 - acc: 0.8638    \n",
      "Epoch 27/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.3701 - acc: 0.8672    \n",
      "Epoch 28/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.3519 - acc: 0.8745    \n",
      "Epoch 29/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.3421 - acc: 0.8778    \n",
      "Epoch 30/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.3310 - acc: 0.8804    \n",
      "Epoch 31/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.3191 - acc: 0.8850    \n",
      "Epoch 32/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.3094 - acc: 0.8883    \n",
      "Epoch 33/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.2963 - acc: 0.8941    \n",
      "Epoch 34/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2894 - acc: 0.8959    \n",
      "Epoch 35/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2738 - acc: 0.9019    \n",
      "Epoch 36/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2729 - acc: 0.9018    \n",
      "Epoch 37/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2654 - acc: 0.9045    \n",
      "Epoch 38/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2527 - acc: 0.9101    \n",
      "Epoch 39/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2514 - acc: 0.9106    \n",
      "Epoch 40/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2427 - acc: 0.9118    \n",
      "Epoch 41/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2403 - acc: 0.9137    \n",
      "Epoch 42/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2299 - acc: 0.9172    \n",
      "Epoch 43/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2276 - acc: 0.9177    \n",
      "Epoch 44/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2174 - acc: 0.9227    \n",
      "Epoch 45/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2123 - acc: 0.9232    \n",
      "Epoch 46/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2061 - acc: 0.9255    \n",
      "Epoch 47/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2040 - acc: 0.9275    \n",
      "Epoch 48/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.2004 - acc: 0.9283    \n",
      "Epoch 49/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1990 - acc: 0.9285    \n",
      "Epoch 50/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1901 - acc: 0.9310    \n",
      "Epoch 51/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1899 - acc: 0.9310    \n",
      "Epoch 52/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1787 - acc: 0.9371    \n",
      "Epoch 53/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1811 - acc: 0.9345    \n",
      "Epoch 54/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1735 - acc: 0.9372    \n",
      "Epoch 55/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1774 - acc: 0.9366    \n",
      "Epoch 56/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1745 - acc: 0.9373    \n",
      "Epoch 57/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1704 - acc: 0.9394    \n",
      "Epoch 58/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1620 - acc: 0.9442    \n",
      "Epoch 59/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1617 - acc: 0.9426    \n",
      "Epoch 60/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1620 - acc: 0.9419    \n",
      "Epoch 61/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1535 - acc: 0.9456    \n",
      "Epoch 62/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1562 - acc: 0.9445    \n",
      "Epoch 63/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1538 - acc: 0.9460    \n",
      "Epoch 64/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1512 - acc: 0.9468    \n",
      "Epoch 65/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1489 - acc: 0.9477    \n",
      "Epoch 66/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1462 - acc: 0.9483    \n",
      "Epoch 67/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1466 - acc: 0.9485    \n",
      "Epoch 68/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1435 - acc: 0.9503    \n",
      "Epoch 69/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1366 - acc: 0.9513    \n",
      "Epoch 70/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1357 - acc: 0.9526    \n",
      "Epoch 71/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1361 - acc: 0.9526    \n",
      "Epoch 72/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1374 - acc: 0.9511    \n",
      "Epoch 73/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1337 - acc: 0.9517    \n",
      "Epoch 74/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1332 - acc: 0.9534    \n",
      "Epoch 75/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1306 - acc: 0.9542    \n",
      "Epoch 76/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1328 - acc: 0.9549    \n",
      "Epoch 77/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1311 - acc: 0.9537    \n",
      "Epoch 78/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1146 - acc: 0.9599    \n",
      "Epoch 79/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1270 - acc: 0.9547    \n",
      "Epoch 80/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1168 - acc: 0.9591    \n",
      "Epoch 81/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1249 - acc: 0.9568    \n",
      "Epoch 82/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1202 - acc: 0.9568    \n",
      "Epoch 83/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1129 - acc: 0.9603    \n",
      "Epoch 84/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1162 - acc: 0.9609    \n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 16s - loss: 0.1167 - acc: 0.9592    \n",
      "Epoch 86/200\n",
      "45000/45000 [==============================] - 17s - loss: 0.1184 - acc: 0.9592    \n",
      "Epoch 87/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1172 - acc: 0.9599    \n",
      "Epoch 88/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1168 - acc: 0.9596    \n",
      "Epoch 89/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.1143 - acc: 0.9606    \n",
      "Epoch 90/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.1044 - acc: 0.9635    \n",
      "Epoch 91/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1126 - acc: 0.9601    \n",
      "Epoch 92/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1061 - acc: 0.9642    \n",
      "Epoch 93/200\n",
      "45000/45000 [==============================] - 17s - loss: 0.1132 - acc: 0.9611    \n",
      "Epoch 94/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.1070 - acc: 0.9625    \n",
      "Epoch 95/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.1047 - acc: 0.9629    \n",
      "Epoch 96/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1046 - acc: 0.9640    \n",
      "Epoch 97/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.1032 - acc: 0.9641    \n",
      "Epoch 98/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1054 - acc: 0.9640    \n",
      "Epoch 99/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.1047 - acc: 0.9654    \n",
      "Epoch 100/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0976 - acc: 0.9657    \n",
      "Epoch 101/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0989 - acc: 0.9660    \n",
      "Epoch 102/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0988 - acc: 0.9660    \n",
      "Epoch 103/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.1005 - acc: 0.9650    \n",
      "Epoch 104/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.1018 - acc: 0.9658    \n",
      "Epoch 105/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0999 - acc: 0.9650    \n",
      "Epoch 106/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0955 - acc: 0.9666    \n",
      "Epoch 107/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.1036 - acc: 0.9660    \n",
      "Epoch 108/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0907 - acc: 0.9689    \n",
      "Epoch 109/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0979 - acc: 0.9668    \n",
      "Epoch 110/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0934 - acc: 0.9683    \n",
      "Epoch 111/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.0929 - acc: 0.9681    \n",
      "Epoch 112/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0922 - acc: 0.9686    \n",
      "Epoch 113/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0934 - acc: 0.9670    \n",
      "Epoch 114/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.0899 - acc: 0.9692    \n",
      "Epoch 115/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.0904 - acc: 0.9702    \n",
      "Epoch 116/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0947 - acc: 0.9684    \n",
      "Epoch 117/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0845 - acc: 0.9713    \n",
      "Epoch 118/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0897 - acc: 0.9691    \n",
      "Epoch 119/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0905 - acc: 0.9685    \n",
      "Epoch 120/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0824 - acc: 0.9712    \n",
      "Epoch 121/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0956 - acc: 0.9674    \n",
      "Epoch 122/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0872 - acc: 0.9706    \n",
      "Epoch 123/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0854 - acc: 0.9708    \n",
      "Epoch 124/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.0851 - acc: 0.9716    \n",
      "Epoch 125/200\n",
      "45000/45000 [==============================] - 17s - loss: 0.0842 - acc: 0.9711    \n",
      "Epoch 126/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0895 - acc: 0.9692    \n",
      "Epoch 127/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0815 - acc: 0.9716    \n",
      "Epoch 128/200\n",
      "45000/45000 [==============================] - 17s - loss: 0.0815 - acc: 0.9726    \n",
      "Epoch 129/200\n",
      "45000/45000 [==============================] - 16s - loss: 0.0859 - acc: 0.9702    \n",
      "Epoch 130/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0860 - acc: 0.9710    \n",
      "Epoch 131/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0801 - acc: 0.9722    \n",
      "Epoch 132/200\n",
      "45000/45000 [==============================] - 13s - loss: 0.0806 - acc: 0.9728    \n",
      "Epoch 133/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0766 - acc: 0.9729    \n",
      "Epoch 134/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0842 - acc: 0.9718    \n",
      "Epoch 135/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0811 - acc: 0.9720    \n",
      "Epoch 136/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0808 - acc: 0.9726    \n",
      "Epoch 137/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0751 - acc: 0.9737    \n",
      "Epoch 138/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0853 - acc: 0.9716    \n",
      "Epoch 139/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0813 - acc: 0.9727    \n",
      "Epoch 140/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0816 - acc: 0.9728    \n",
      "Epoch 141/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0762 - acc: 0.9732    \n",
      "Epoch 142/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0783 - acc: 0.9739    \n",
      "Epoch 143/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0747 - acc: 0.9753    \n",
      "Epoch 144/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0748 - acc: 0.9745    \n",
      "Epoch 145/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0731 - acc: 0.9751    \n",
      "Epoch 146/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0746 - acc: 0.9747    \n",
      "Epoch 147/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0793 - acc: 0.9730    \n",
      "Epoch 148/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0727 - acc: 0.9752    \n",
      "Epoch 149/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0720 - acc: 0.9757    \n",
      "Epoch 150/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0713 - acc: 0.9748    \n",
      "Epoch 151/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0724 - acc: 0.9752    \n",
      "Epoch 152/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0758 - acc: 0.9747    \n",
      "Epoch 153/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0714 - acc: 0.9756    \n",
      "Epoch 154/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0695 - acc: 0.9764    \n",
      "Epoch 155/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0702 - acc: 0.9762    \n",
      "Epoch 156/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0762 - acc: 0.9750    \n",
      "Epoch 157/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0720 - acc: 0.9755    \n",
      "Epoch 158/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0747 - acc: 0.9756    \n",
      "Epoch 159/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0678 - acc: 0.9772    \n",
      "Epoch 160/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0684 - acc: 0.9772    \n",
      "Epoch 161/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0716 - acc: 0.9755    \n",
      "Epoch 162/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0694 - acc: 0.9766    \n",
      "Epoch 163/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0695 - acc: 0.9770    \n",
      "Epoch 164/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0714 - acc: 0.9760    \n",
      "Epoch 165/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0662 - acc: 0.9778    \n",
      "Epoch 166/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0721 - acc: 0.9751    \n",
      "Epoch 167/200\n",
      "45000/45000 [==============================] - 15s - loss: 0.0617 - acc: 0.9786    \n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 14s - loss: 0.0706 - acc: 0.9763    \n",
      "Epoch 169/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0677 - acc: 0.9771    \n",
      "Epoch 170/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0597 - acc: 0.9793    \n",
      "Epoch 171/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0717 - acc: 0.9762    \n",
      "Epoch 172/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0659 - acc: 0.9779    \n",
      "Epoch 173/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0750 - acc: 0.9750    \n",
      "Epoch 174/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0627 - acc: 0.9789    \n",
      "Epoch 175/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0647 - acc: 0.9777    \n",
      "Epoch 176/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0607 - acc: 0.9799    \n",
      "Epoch 177/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0680 - acc: 0.9779    \n",
      "Epoch 178/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0630 - acc: 0.9790    \n",
      "Epoch 179/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0656 - acc: 0.9785    \n",
      "Epoch 180/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0680 - acc: 0.9781    \n",
      "Epoch 181/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0622 - acc: 0.9797    \n",
      "Epoch 182/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0591 - acc: 0.9803    \n",
      "Epoch 183/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0650 - acc: 0.9776    \n",
      "Epoch 184/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0617 - acc: 0.9788    \n",
      "Epoch 185/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0619 - acc: 0.9790    \n",
      "Epoch 186/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0661 - acc: 0.9778    \n",
      "Epoch 187/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0595 - acc: 0.9804    \n",
      "Epoch 188/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0602 - acc: 0.9812    \n",
      "Epoch 189/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0564 - acc: 0.9809    \n",
      "Epoch 190/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0640 - acc: 0.9780    \n",
      "Epoch 191/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0627 - acc: 0.9791    \n",
      "Epoch 192/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0651 - acc: 0.9787    \n",
      "Epoch 193/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0589 - acc: 0.9801    \n",
      "Epoch 194/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0569 - acc: 0.9809    \n",
      "Epoch 195/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0650 - acc: 0.9778    \n",
      "Epoch 196/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0574 - acc: 0.9799    \n",
      "Epoch 197/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0592 - acc: 0.9802    \n",
      "Epoch 198/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0584 - acc: 0.9812    \n",
      "Epoch 199/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0615 - acc: 0.9799    \n",
      "Epoch 200/200\n",
      "45000/45000 [==============================] - 14s - loss: 0.0592 - acc: 0.9797    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38bc19a1d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFARModel.fit(x = train_set ,y = train_out, epochs = 200 , batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704/5000 [===========================>..] - ETA: 0s\n",
      "Loss = 3.5883034523\n",
      "Test Accuracy = 0.6218\n"
     ]
    }
   ],
   "source": [
    "preds = CIFARModel.evaluate(x = validation_set, y = validation_out)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
